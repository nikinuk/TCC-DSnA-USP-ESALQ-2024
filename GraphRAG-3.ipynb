{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community neo4j scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Chaves para modelos\n",
    "os.environ['OPENAI_API_KEY'] = \"YOUR OPENAI KEY\"\n",
    "os.environ[\"NEO4J_URI\"] = \"YOUR NEO4J URI\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" \n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"YOUR NEO4J KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Criação do grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = 'neo4j'\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "kg = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "candidato {nome: STRING, partido: STRING, coalizao: STRING, vice: STRING}\n",
      "plano {source: STRING, doc_id: STRING}\n",
      "eixo {nome: STRING, Header_1: STRING, texto: STRING, STD_Header: STRING, Header_2: STRING}\n",
      "ponto {nome: STRING, texto: STRING, tipo: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:candidato)-[:planeja]->(:plano)\n",
      "(:plano)-[:contem]->(:eixo)\n",
      "(:eixo)-[:propoe]->(:ponto)\n",
      "(:eixo)-[:seq]->(:eixo)\n",
      "(:ponto)-[:relacionado_com]->(:ponto)\n"
     ]
    }
   ],
   "source": [
    "kg.refresh_schema()\n",
    "schema = kg.schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index in list A: 0, Index in list B: 0, Cosine Similarity: 0.9915\n",
      "Index in list A: 1, Index in list B: 0, Cosine Similarity: 0.9450\n",
      "Index in list A: 2, Index in list B: 0, Cosine Similarity: 0.9244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar_pairs(list_A, list_B):\n",
    "    # Compute cosine similarity between all pairs\n",
    "    similarities = cosine_similarity(list_A, list_B)\n",
    "    \n",
    "    # Find the most similar pairs\n",
    "    most_similar_pairs = []\n",
    "    for i, row in enumerate(similarities):\n",
    "        j = np.argmax(row)\n",
    "        most_similar_pairs.append((i, j, row[j]))\n",
    "    \n",
    "    return most_similar_pairs\n",
    "\n",
    "# Example usage\n",
    "list_A = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]]\n",
    "list_B = [[0.1, 0.2, 0.4], [0.4, -0.5, 0.6], [0.7, 0, 0.9]]\n",
    "\n",
    "most_similar_pairs = find_most_similar_pairs(list_A, list_B)\n",
    "for pair in most_similar_pairs:\n",
    "    print(f\"Index in list A: {pair[0]}, Index in list B: {pair[1]}, Cosine Similarity: {pair[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('entidades_full.pkl', 'rb') as f:\n",
    "    final_json = pickle.load(f)\n",
    "\n",
    "with open('STD_documents.pkl', 'rb') as f:\n",
    "    all_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "outer loop: 100%|██████████| 481/481 [31:25<00:00,  3.92s/it]  \n"
     ]
    }
   ],
   "source": [
    "for entity in tqdm(final_json, desc=\"outer loop\"):\n",
    "\n",
    "    # Criar candidato se não ainda houver\n",
    "    doc = [doc for doc in all_docs if doc.id == entity['doc_id']][0]\n",
    "    cypher = 'MERGE (n:candidato { nome: \"' + doc.metadata['candidato'] + '\"}) ON CREATE SET n.nome = \"' + doc.metadata['candidato'] + '\", n.partido = \"' + doc.metadata['partido'] + '\", n.coalizao = \"' + doc.metadata['coalizao'] + '\", n.vice = \"' + doc.metadata['vice'] + '\"'\n",
    "    kg.query(cypher)\n",
    "\n",
    "   # Criar plano de governo, se ...\n",
    "    cypher = 'MERGE (n:plano { source: \"' + doc.metadata['source'] + '\"}) ON CREATE SET n.source = \"' + doc.metadata['source'] +'\", n.doc_id = \"' + entity['doc_id'] + '\"'\n",
    "    kg.query(cypher)\n",
    "\n",
    "    # Ligar Candidato e plano\n",
    "    cypher = 'MATCH (n1:candidato {nome: \"' + doc.metadata['candidato'] + '\"}), (n2:plano {source: \"' + doc.metadata['source'] + '\"}) MERGE (n1)-[hasRelationship:planeja]->(n2)'\n",
    "    kg.query(cypher)\n",
    "\n",
    "    # Criar chunks (eixos)\n",
    "    nome_eixo = entity['doc_id'] + \"- \" + doc.metadata['STD_Header']\n",
    "    cypher = 'MERGE (n:eixo { nome: \"' + nome_eixo + '\"}) ON CREATE SET n.nome = \"' + nome_eixo + '\", n.Header_1 = \"' + doc.metadata['Header_1'] + '\", n.texto = \"' + doc.page_content + '\", n.STD_Header = \"' + doc.metadata['STD_Header'] + '\"'\n",
    "    kg.query(cypher)\n",
    "    if \"Header_2\" in doc.metadata:\n",
    "        cypher = 'MATCH (n:eixo) WHERE n.nome = \"' + nome_eixo + '\" SET n.Header_2 = \"' + doc.metadata['Header_2'] + '\"'\n",
    "        kg.query(cypher)\n",
    "\n",
    "    #Ligar Chunks (eixo) ao plano\n",
    "    cypher = 'MATCH (n1:plano {source: \"' + doc.metadata['source'] + '\"}), (n2:eixo {nome: \"' + nome_eixo + '\"}) MERGE (n1)-[hasRelationship:contem]->(n2)'\n",
    "    kg.query(cypher)\n",
    "\n",
    "    # Sequencia chuncks\n",
    "    if int(entity['doc_id'][-2:]) > 0:\n",
    "        id1 = entity['doc_id'][0:-2] + f\"{(int(doc.id[-2:])-1):02d}\"\n",
    "        cypher = 'MATCH (n1:eixo {nome: \"' + id1 + \"- \" + doc.metadata['STD_Header'] + '\"}), (n2:eixo {nome: \"' + nome_eixo + '\"}) MERGE (n1)-[hasRelationship:seq]->(n2)'\n",
    "        kg.query(cypher)\n",
    "\n",
    "\n",
    "    #Criar valores e propostas e suas interrelações\n",
    "    for element in entity['elements']:\n",
    "        if element['item_type'] == 'node':\n",
    "            # Criar node\n",
    "            cypher = 'MERGE (n:ponto { nome: \"' + element['node_name'] + '\"}) ON CREATE SET n.nome = \"' + element['node_name'] +'\", n.tipo = \"' + element['node_type'] +'\", n.candidato = \"' + doc.metadata['candidato'] + '\", n.texto = \"' + element['node_description'] + '\"'\n",
    "            kg.query(cypher)\n",
    "            # Ligar node com eixo\n",
    "            cypher = 'MATCH (n1:eixo {nome: \"' + nome_eixo + '\"}), (n2:ponto {nome: \"' + element['node_name'] + '\"}) MERGE (n1)-[hasRelationship:propoe]->(n2)'\n",
    "            kg.query(cypher)\n",
    "        else:\n",
    "            #Ligar sub Chunks\n",
    "            cypher = 'MATCH (n1 {nome: \"' + element['head_node'] + '\"}), (n2 {nome: \"' + element['tail_node'] + '\"}) MERGE (n1)-[hasRelationship:relacionado_com]->(n2)'\n",
    "            kg.query(cypher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criar text index para nomes de propostas e valores e eixos\n",
    "\n",
    "cypher = \"CREATE FULLTEXT INDEX `proposta_tidx` IF NOT EXISTS FOR (n:ponto) ON EACH [n.nome]\"\n",
    "kg.query(cypher)\n",
    "cypher = \"CREATE FULLTEXT INDEX `eixo_tidx` IF NOT EXISTS FOR (n:eixo) ON EACH [n.STD_Header]\"\n",
    "kg.query(cypher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar embedings para texto dos pontos (propostas e valores)\n",
    "cypher = \"CREATE VECTOR INDEX ponto_vidx IF NOT EXISTS FOR (n:ponto) ON (n.textEmbedding) OPTIONS { indexConfig: {`vector.dimensions`: 3072, `vector.similarity_function`: 'cosine' }}\"\n",
    "kg.query(cypher)\n",
    "cypher = 'MATCH (n:ponto) WHERE n.textEmbedding IS NULL WITH n, genai.vector.encode(n.texto, \"OpenAI\", {token:\"' + OPENAI_API_KEY + '\", model:\"text-embedding-3-large\"}) AS vector CALL db.create.setNodeVectorProperty(n, \"textEmbedding\", vector)'\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "candidato {nome: STRING, partido: STRING, coalizao: STRING, vice: STRING}\n",
      "plano {source: STRING, doc_id: STRING}\n",
      "eixo {nome: STRING, Header_1: STRING, texto: STRING, STD_Header: STRING, Header_2: STRING}\n",
      "ponto {nome: STRING, texto: STRING, tipo: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:candidato)-[:planeja]->(:plano)\n",
      "(:plano)-[:contem]->(:eixo)\n",
      "(:eixo)-[:propoe]->(:ponto)\n",
      "(:eixo)-[:seq]->(:eixo)\n",
      "(:ponto)-[:relacionado_com]->(:ponto)\n"
     ]
    }
   ],
   "source": [
    "kg.refresh_schema()\n",
    "schema = kg.schema\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a similaridade entre cosenos de cada par de pontos nas propostas\n",
    "def find_most_similar_pairs(list_A, list_B):\n",
    "    \n",
    "    similarities = cosine_similarity(list_A, list_B)\n",
    "    \n",
    "    # Find the most similar pairs\n",
    "    most_similar_pairs = []\n",
    "    for i, row in enumerate(similarities):\n",
    "        j = np.argmax(row)\n",
    "        most_similar_pairs.append((i, j, row[j]))\n",
    "    \n",
    "    return most_similar_pairs\n",
    "\n",
    "# Lista de planos ('doc_ids)\n",
    "cypher=\"MATCH (p:plano) RETURN p.doc_id\"\n",
    "planos = kg.query(cypher)\n",
    "\n",
    "# Para cada plano\n",
    "# coletar lista de embeddings: [{'plano': 'doc_i', 'embeddings', []}]\n",
    "embeddings = []\n",
    "for plano in tqdm(planos):\n",
    "    doc_id = plano['p.doc_id']\n",
    "    response = kg.query(\"MATCH (p:plano {doc_id:'\" + doc_id + \"'})-[:contem]->(:eixo)-[:propoe]->(pto:ponto) RETURN elementId(pto), pto.textEmbedding\")\n",
    "    id_list = []\n",
    "    embedding_list = []\n",
    "    for r in response:\n",
    "        id_list.append(r['elementId(pto)'])\n",
    "        embedding_list.append(r['pto.textEmbedding'])\n",
    "    embeddings.append({'ids':id_list, 'embeddings':embedding_list})\n",
    "\n",
    "# Criar ligações contendo a distância como propriedade\n",
    "for i in tqdm(range(len(planos))):\n",
    "    for j in range(len(planos)):\n",
    "        if not planos[i]['p.doc_id'] == planos[j]['p.doc_id']:\n",
    "            nearest_neighbors = find_most_similar_pairs(embeddings[i]['embeddings'], embeddings[j]['embeddings'])\n",
    "            # Criar relações no grafo\n",
    "            for n in nearest_neighbors:\n",
    "                cypher = \"MATCH (a:ponto), (b:ponto) WHERE elementId(a)='\" + embeddings[i]['ids'][n[0]] + \"' AND elementId(b)='\" + embeddings[j]['ids'][n[1]] + \"' CREATE (a)-[:similar_to {cos_similarity:\" + str(n[2]) + \"}]->(b)\"\n",
    "                kg.query(cypher)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAGvEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
