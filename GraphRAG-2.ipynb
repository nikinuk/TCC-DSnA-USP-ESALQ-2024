{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação para vEnv\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"YOUR_KEY_PLEASE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extrair Visões e Propostas dos textos dos planos de governo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar documentos preprocessados\n",
    "with open('STD_documents.pkl', 'rb') as f:\n",
    "    all_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 107988\n",
      "Number of chars: 720957\n"
     ]
    }
   ],
   "source": [
    "num_chars=0\n",
    "num_words = 0\n",
    "for doc in all_docs:\n",
    "    st = str(doc.page_content)\n",
    "    num_chars = num_chars + len(st)\n",
    "    words = st.split()\n",
    "    num_words = num_words + len(words)\n",
    "\n",
    "print(\"Number of words:\", num_words)\n",
    "print(\"Number of chars:\", num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chave para acesso ao API da OepnAI\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator para medição de tempos\n",
    "def timeit(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"  - tempo de operação {end_time - start_time:.1f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Chamada ao GPT 4 Turbo\n",
    "@timeit\n",
    "def extract_information(text, doc_id, model=\"gpt-4o-mini\"):\n",
    "   completion = client.chat.completions.create(\n",
    "        model=model, # Gpt 4 é um excelente custo beneficio para este uso\n",
    "        temperature=0, # Não queremos criatividade, apenas análise semântica\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt # Parâmetro para prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt.format(\n",
    "              entity_types=node_types,\n",
    "              specification=\"## Documento:\" + doc_id + \"\\n## Conteúdo:\" + text\n",
    "            ) # Parâmetros para composição do prompt\n",
    "        }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "   return completion.choices[0].message.content, completion.usage.total_tokens\n",
    "\n",
    "\n",
    "# Definição da função do assitente\n",
    "system_prompt = \"\"\"\n",
    "Você é um agente especializado em analizar documentos que descrevem planos de governo e contêm, entre outras informações, os valores e as propostas dos candidatos ao cargo de prefeito de Curitiba.\n",
    "Você recebe trechos dos documentos identificado com um DOC_ID. Sua tarefa é identifocar em cada document as propostas e os valores citados (node), bem como se existe relações entre eles (link).\n",
    "Você deve gerar o OUTPUT em formato JSON. Este JSON deve conter objetos com as seguintes chaves:\n",
    "\"item_type\", que é a chave que identifica se o objeto se refere a um nó (node) ou a uma ligação (link).\n",
    "Se o objeto for um nó, deve conter a chave \"node_name\", com o nome do nó, \"node_type\" com o tipo de nó e \"node_description\", com a descrição do nó.\n",
    "Se o objeto for uma ligação, deve trazer os nomes dos nós que são relacionados, usando as chaves \"head_node\" e \"tail_node\".\n",
    "Tente sempre extrair o maior número de valores e propostas contidos documento fornecido.\n",
    "A linguagem a ser sempre utilizada é o Português do Brasil.\"\"\"\n",
    "\n",
    "# Definição da estrutura do prompt\n",
    "user_prompt = \"\"\"\n",
    "Baseado no exemplo fornecido, extraia os itens, ou seja, os valores, propostas e ligações contidos nos documentos DOC_ID fornecidos.\n",
    "Como definição de valor usar: \"Apreço e estimação: Valor é o apreço e estimação que se tem por algo ou alguém. Normas sociais: Valores são normas ou padrões sociais que orientam a ação humana e são geralmente aceitos por um indivíduo, classe ou sociedade. Pode descrever visões, anseios e desejos de quem os tem.\"\n",
    "Como definição de proposta usar: \"Aquilo que se está prometendo ou sugerindo que seja realizado.\"\n",
    "\n",
    "--> Início do Exemplo:\n",
    "\n",
    "## Documento: NICHO04\n",
    "## Conteúdo: É preciso mudar o atual cenário de abandono de nosso município, para tanto tem\n",
    "que se colocar em prática o plano diretor, e dos instrumentos nele previstos para o uso\n",
    "ordenado do solo urbano, com obras de infraestrutura que proporcionem um melhor\n",
    "escoamento das águas pluviais, evitando as enchentes em épocas de chuvas. Elaborar\n",
    "projetos para a reestruturação do sistema viário com readequação das vias que dão\n",
    "acesso a PR-407, acabando com as longas filas de veículos nos feriadões, e em época\n",
    "de temporada.\n",
    "Modernizar o sistema de transporte coletivo no município, fazendo com que as\n",
    "empresas façam atendimento também ao interior dos principais balneários e colônias, e\n",
    "não somente pela PR-412, além de fazer a integração com os municípios de Matinhos e\n",
    "Paranaguá, em razão do grande número de usuários, estudantes, trabalhadores e\n",
    "turistas que se deslocam diariamente para estes municípios, com uma tarifa social justa.\n",
    "Construção de um terminal rodoviário municipal moderno, capaz de atender a população,\n",
    "visitantes e aos turistas.\n",
    "Envidar esforços com o objetivo de municipalizar a PR 412, transformando-a em\n",
    "uma avenida revitalizada, moderna, com arborização, estacionamentos, infraestrutura de\n",
    "escoamento de águas pluviais, galerias, manilhamentos, boca de lobo, evitando as\n",
    "enchentes em épocas de grandes chuvas.\n",
    "Revitalização da Av. Beira Mar, com calçadas padronizadas, ciclovias, iluminação\n",
    "moderna, arborização, cuidado com a restinga, restauração dos banheiros que estão\n",
    "abandonados, e construções de novos, nos balneários, manutenção e construção dos\n",
    "decks de acesso a praia em todos os balneários.\n",
    "Obras planejadas com o objetivo de escoamento das águas pluviais das vias\n",
    "públicas; limpezas periódicas e desassoreamento dos canais desenvolver esforços junto\n",
    "ao Estado e a União com o escopo de concluir as obras de saneamento básico no\n",
    "município, posto que Pontal do Paraná é um município voltado para o turismo de veraneio\n",
    "e praias.\n",
    "Colocar placas de identificação nas vias públicas, e de identificação nos balneários\n",
    "na Avenida Beira Mar.\n",
    "Construir portais modernos nas divisas com Matinhos, e Paranaguá, acabando\n",
    "com a sensação de abandono em que o município se encontra.\n",
    "Fazer obras de pavimentação asfáltica e calçamentos padronizados nas ruas e\n",
    "avenidas, com colocação de semáforos, proporcionando mais segurança aos usuários.\n",
    "\n",
    "\n",
    "## Output\n",
    "[\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Mudar o atual cenário de abandono do município.\",\n",
    "    \"node_type\": \"valor\",\n",
    "    \"node_description\": \"É preciso mudar o atual cenário de abandono de nosso município, para tanto tem que se colocar em prática o plano diretor, e dos instrumentos nele previstos para o uso ordenado do solo urbano, com obras de infraestrutura que proporcionem um melhor escoamento das águas pluviais, evitando as enchentes em épocas de chuvas.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Reestruturação do sistema viário de acesso à PR-407.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Elaborar projetos para a reestruturação do sistema viário com readequação das vias que dão acesso a PR-407, acabando com as longas filas de veículos nos feriadões, e em época de temporada.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"link\",\n",
    "    \"head_node\": \"Reestruturação do sistema viário de acesso à PR-407.\",\n",
    "    \"tail_node\": \"Mudar o atual cenário de abandono do município.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Modernização do o sistema de transporte coletivo.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Modernizar o sistema de transporte coletivo no município, fazendo com que as empresas façam atendimento também ao interior dos principais balneários e colônias, e não somente pela PR-412.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Fazer a integração com os municípios de Matinhos e Paranaguá.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Fazer a integração com os municípios de Matinhos e Paranaguá, em razão do grande número de usuários, estudantes, trabalhadores e turistas que se deslocam diariamente para estes municípios, com uma tarifa social justa.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"link\",\n",
    "    \"head_node\": \"Fazer a integração com os municípios de Matinhos e Paranaguá.\",\n",
    "    \"tail_node\": \"Modernização do o sistema de transporte coletivo.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Construção de um novo terminal rodoviário.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Construção de um terminal rodoviário municipal moderno, capaz de atender a população, visitantes e aos turistas.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"link\",\n",
    "    \"head_node\": \"Construção de um novo terminal rodoviário.\",\n",
    "    \"tail_node\": \"Modernização do o sistema de transporte coletivo.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Municipalização da PR 412.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Envidar esforços com o objetivo de municipalizar a PR 412, transformando-a em uma avenida revitalizada, moderna, com arborização, estacionamentos, infraestrutura de escoamento de águas pluviais, galerias, manilhamentos, boca de lobo, evitando as enchentes em épocas de grandes chuvas.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Revitalização da Av. Beira Mar.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Revitalização da Av. Beira Mar, com calçadas padronizadas, ciclovias, iluminação moderna, arborização, cuidado com a restinga, restauração dos banheiros que estão abandonados, e construções de novos, nos balneários, manutenção e construção dos decks de acesso a praia em todos os balneários.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Conclusão de obras de saneamento básico.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Obras planejadas com o objetivo de escoamento das águas pluviais das vias públicas; limpezas periódicas e desassoreamento dos canais desenvolver esforços junto ao Estado e a União com o escopo de concluir as obras de saneamento básico no município, posto que Pontal do Paraná é um município voltado para o turismo de veraneio e praias.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Identificação de vias públicas.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Colocar placas de identificação nas vias públicas, e de identificação nos balneários na Avenida Beira Mar.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Identificação das divisas.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Construir portais modernos nas divisas com Matinhos, e Paranaguá, acabando com a sensação de abandono em que o município se encontra.\"\n",
    "  }},\n",
    "  {{\n",
    "    \"item_type\": \"node\",\n",
    "    \"node_name\": \"Pavimentação e sinalização das ruas.\",\n",
    "    \"node_type\": \"proposta\",\n",
    "    \"node_description\": \"Fazer obras de pavimentação asfáltica e calçamentos padronizados nas ruas e avenidas, com colocação de semáforos, proporcionando mais segurança aos usuários.\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "--> Fim do exemplo\n",
    "\n",
    "Para o documento a seguir, extrair as propstas, valores e quais propostas e valores são relacionadas.\n",
    "{specification}\n",
    "\n",
    "## Output\n",
    "\"\"\"\n",
    "\n",
    "#find first '[' and last ']' in string\n",
    "# Esta função apenas verifica se o GPT retornou uma lista ou um text, transformando texto para lista\n",
    "import json\n",
    "\n",
    "def find_brackets(string):\n",
    "    first = 0\n",
    "    for i in range(len(string)):\n",
    "        if string[i] == '[' and first==0:\n",
    "            first = i\n",
    "        if string[i] == ']':\n",
    "            last = i\n",
    "    return first, last\n",
    "\n",
    "# transform text to json\n",
    "def text_to_json(text):\n",
    "    json_data = json.loads(text)\n",
    "    return json_data\n",
    "\n",
    "def ajustar_output(output):\n",
    "    if not isinstance(output, list):\n",
    "        f, l = find_brackets(output)\n",
    "        return text_to_json(output[f:l+1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_id ANDRE00 - Chunk # 1 de 2\n",
      "  - tempo de operação 15.4s\n",
      "3387 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE00 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.0s\n",
      "2542 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE01 - Chunk # 1 de 14\n",
      "  - tempo de operação 9.1s\n",
      "2956 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE01 - Chunk # 2 de 14\n",
      "  - tempo de operação 14.0s\n",
      "3153 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE01 - Chunk # 3 de 14\n",
      "  - tempo de operação 13.2s\n",
      "3114 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE01 - Chunk # 4 de 14\n",
      "  - tempo de operação 15.6s\n",
      "3281 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE01 - Chunk # 5 de 14\n",
      "  - tempo de operação 14.6s\n",
      "3266 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE01 - Chunk # 6 de 14\n",
      "  - tempo de operação 13.6s\n",
      "3125 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE01 - Chunk # 7 de 14\n",
      "  - tempo de operação 15.6s\n",
      "3106 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE01 - Chunk # 8 de 14\n",
      "  - tempo de operação 16.3s\n",
      "3177 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE01 - Chunk # 9 de 14\n",
      "  - tempo de operação 13.7s\n",
      "2946 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE01 - Chunk # 10 de 14\n",
      "  - tempo de operação 23.5s\n",
      "3493 tokens usados para extrair 14 relações\n",
      "doc_id ANDRE01 - Chunk # 11 de 14\n",
      "  - tempo de operação 25.0s\n",
      "3556 tokens usados para extrair 15 relações\n",
      "doc_id ANDRE01 - Chunk # 12 de 14\n",
      "  - tempo de operação 33.2s\n",
      "3770 tokens usados para extrair 20 relações\n",
      "doc_id ANDRE01 - Chunk # 13 de 14\n",
      "  - tempo de operação 37.5s\n",
      "3922 tokens usados para extrair 22 relações\n",
      "doc_id ANDRE01 - Chunk # 14 de 14\n",
      "  - tempo de operação 22.9s\n",
      "3399 tokens usados para extrair 15 relações\n",
      "doc_id ANDRE02 - Chunk # 1 de 10\n",
      "  - tempo de operação 12.1s\n",
      "3258 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE02 - Chunk # 2 de 10\n",
      "  - tempo de operação 7.9s\n",
      "2832 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE02 - Chunk # 3 de 10\n",
      "  - tempo de operação 12.4s\n",
      "3135 tokens usados para extrair 8 relações\n",
      "doc_id ANDRE02 - Chunk # 4 de 10\n",
      "  - tempo de operação 19.1s\n",
      "3857 tokens usados para extrair 20 relações\n",
      "doc_id ANDRE02 - Chunk # 5 de 10\n",
      "  - tempo de operação 8.4s\n",
      "2932 tokens usados para extrair 6 relações\n",
      "doc_id ANDRE02 - Chunk # 6 de 10\n",
      "  - tempo de operação 10.0s\n",
      "3023 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE02 - Chunk # 7 de 10\n",
      "  - tempo de operação 17.1s\n",
      "3467 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE02 - Chunk # 8 de 10\n",
      "  - tempo de operação 14.0s\n",
      "3217 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE02 - Chunk # 9 de 10\n",
      "  - tempo de operação 12.8s\n",
      "3293 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE02 - Chunk # 10 de 10\n",
      "  - tempo de operação 10.2s\n",
      "3006 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE03 - Chunk # 1 de 7\n",
      "  - tempo de operação 12.0s\n",
      "3141 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE03 - Chunk # 2 de 7\n",
      "  - tempo de operação 13.4s\n",
      "3164 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE03 - Chunk # 3 de 7\n",
      "  - tempo de operação 14.7s\n",
      "3287 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE03 - Chunk # 4 de 7\n",
      "  - tempo de operação 18.3s\n",
      "3444 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE03 - Chunk # 5 de 7\n",
      "  - tempo de operação 11.1s\n",
      "3130 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE03 - Chunk # 6 de 7\n",
      "  - tempo de operação 9.6s\n",
      "3192 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE03 - Chunk # 7 de 7\n",
      "  - tempo de operação 8.2s\n",
      "2815 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE04 - Chunk # 1 de 6\n",
      "  - tempo de operação 5.0s\n",
      "2784 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE04 - Chunk # 2 de 6\n",
      "  - tempo de operação 15.0s\n",
      "3113 tokens usados para extrair 8 relações\n",
      "doc_id ANDRE04 - Chunk # 3 de 6\n",
      "  - tempo de operação 9.9s\n",
      "3109 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE04 - Chunk # 4 de 6\n",
      "  - tempo de operação 13.6s\n",
      "3371 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE04 - Chunk # 5 de 6\n",
      "  - tempo de operação 14.6s\n",
      "3555 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE04 - Chunk # 6 de 6\n",
      "  - tempo de operação 12.9s\n",
      "3313 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE05 - Chunk # 1 de 10\n",
      "  - tempo de operação 8.2s\n",
      "2773 tokens usados para extrair 6 relações\n",
      "doc_id ANDRE05 - Chunk # 2 de 10\n",
      "  - tempo de operação 5.7s\n",
      "2894 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE05 - Chunk # 3 de 10\n",
      "  - tempo de operação 17.8s\n",
      "3373 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE05 - Chunk # 4 de 10\n",
      "  - tempo de operação 17.0s\n",
      "3433 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE05 - Chunk # 5 de 10\n",
      "  - tempo de operação 13.1s\n",
      "3437 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE05 - Chunk # 6 de 10\n",
      "  - tempo de operação 16.6s\n",
      "3356 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE05 - Chunk # 7 de 10\n",
      "  - tempo de operação 24.6s\n",
      "3596 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE05 - Chunk # 8 de 10\n",
      "  - tempo de operação 31.7s\n",
      "3640 tokens usados para extrair 17 relações\n",
      "doc_id ANDRE05 - Chunk # 9 de 10\n",
      "  - tempo de operação 21.2s\n",
      "3593 tokens usados para extrair 14 relações\n",
      "doc_id ANDRE05 - Chunk # 10 de 10\n",
      "  - tempo de operação 5.3s\n",
      "2556 tokens usados para extrair 4 relações\n",
      "doc_id ANDRE06 - Chunk # 1 de 4\n",
      "  - tempo de operação 6.2s\n",
      "2778 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE06 - Chunk # 2 de 4\n",
      "  - tempo de operação 5.2s\n",
      "2721 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE06 - Chunk # 3 de 4\n",
      "  - tempo de operação 23.6s\n",
      "3532 tokens usados para extrair 15 relações\n",
      "doc_id ANDRE06 - Chunk # 4 de 4\n",
      "  - tempo de operação 5.8s\n",
      "2411 tokens usados para extrair 3 relações\n",
      "doc_id ANDRE07 - Chunk # 1 de 18\n",
      "  - tempo de operação 16.2s\n",
      "3267 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE07 - Chunk # 2 de 18\n",
      "  - tempo de operação 15.8s\n",
      "3397 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE07 - Chunk # 3 de 18\n",
      "  - tempo de operação 19.6s\n",
      "3357 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE07 - Chunk # 4 de 18\n",
      "  - tempo de operação 17.1s\n",
      "3304 tokens usados para extrair 12 relações\n",
      "doc_id ANDRE07 - Chunk # 5 de 18\n",
      "  - tempo de operação 10.3s\n",
      "3282 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE07 - Chunk # 6 de 18\n",
      "  - tempo de operação 11.1s\n",
      "3376 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE07 - Chunk # 7 de 18\n",
      "  - tempo de operação 18.3s\n",
      "3135 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE07 - Chunk # 8 de 18\n",
      "  - tempo de operação 10.4s\n",
      "2793 tokens usados para extrair 6 relações\n",
      "doc_id ANDRE07 - Chunk # 9 de 18\n",
      "  - tempo de operação 15.8s\n",
      "3140 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE07 - Chunk # 10 de 18\n",
      "  - tempo de operação 19.4s\n",
      "3269 tokens usados para extrair 10 relações\n",
      "doc_id ANDRE07 - Chunk # 11 de 18\n",
      "  - tempo de operação 18.7s\n",
      "3248 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE07 - Chunk # 12 de 18\n",
      "  - tempo de operação 12.3s\n",
      "3191 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE07 - Chunk # 13 de 18\n",
      "  - tempo de operação 22.7s\n",
      "3758 tokens usados para extrair 17 relações\n",
      "doc_id ANDRE07 - Chunk # 14 de 18\n",
      "  - tempo de operação 9.3s\n",
      "3075 tokens usados para extrair 9 relações\n",
      "doc_id ANDRE07 - Chunk # 15 de 18\n",
      "  - tempo de operação 12.7s\n",
      "3266 tokens usados para extrair 11 relações\n",
      "doc_id ANDRE07 - Chunk # 16 de 18\n",
      "  - tempo de operação 22.7s\n",
      "3650 tokens usados para extrair 17 relações\n",
      "doc_id ANDRE07 - Chunk # 17 de 18\n",
      "  - tempo de operação 5.2s\n",
      "2886 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE07 - Chunk # 18 de 18\n",
      "  - tempo de operação 14.4s\n",
      "3479 tokens usados para extrair 15 relações\n",
      "doc_id ANDRE08 - Chunk # 1 de 5\n",
      "  - tempo de operação 5.3s\n",
      "2897 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE08 - Chunk # 2 de 5\n",
      "  - tempo de operação 9.5s\n",
      "3074 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE08 - Chunk # 3 de 5\n",
      "  - tempo de operação 13.9s\n",
      "3336 tokens usados para extrair 14 relações\n",
      "doc_id ANDRE08 - Chunk # 4 de 5\n",
      "  - tempo de operação 17.1s\n",
      "3773 tokens usados para extrair 20 relações\n",
      "doc_id ANDRE08 - Chunk # 5 de 5\n",
      "  - tempo de operação 6.0s\n",
      "2533 tokens usados para extrair 5 relações\n",
      "doc_id ANDRE09 - Chunk # 1 de 3\n",
      "  - tempo de operação 12.1s\n",
      "3411 tokens usados para extrair 13 relações\n",
      "doc_id ANDRE09 - Chunk # 2 de 3\n",
      "  - tempo de operação 7.8s\n",
      "2948 tokens usados para extrair 7 relações\n",
      "doc_id ANDRE09 - Chunk # 3 de 3\n",
      "  - tempo de operação 4.6s\n",
      "2560 tokens usados para extrair 3 relações\n",
      "doc_id EDUAR00 - Chunk # 1 de 6\n",
      "  - tempo de operação 10.4s\n",
      "3052 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR00 - Chunk # 2 de 6\n",
      "  - tempo de operação 8.7s\n",
      "3102 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR00 - Chunk # 3 de 6\n",
      "  - tempo de operação 19.4s\n",
      "3935 tokens usados para extrair 26 relações\n",
      "doc_id EDUAR00 - Chunk # 4 de 6\n",
      "  - tempo de operação 8.4s\n",
      "3059 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR00 - Chunk # 5 de 6\n",
      "  - tempo de operação 12.8s\n",
      "3410 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR00 - Chunk # 6 de 6\n",
      "  - tempo de operação 6.7s\n",
      "2656 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR01 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.1s\n",
      "3109 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR02 - Chunk # 1 de 1\n",
      "  - tempo de operação 2.6s\n",
      "2341 tokens usados para extrair 1 relações\n",
      "doc_id EDUAR03 - Chunk # 1 de 2\n",
      "  - tempo de operação 12.4s\n",
      "3225 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR03 - Chunk # 2 de 2\n",
      "  - tempo de operação 11.2s\n",
      "3208 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR04 - Chunk # 1 de 2\n",
      "  - tempo de operação 7.9s\n",
      "3055 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR04 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.9s\n",
      "2733 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR05 - Chunk # 1 de 3\n",
      "  - tempo de operação 12.7s\n",
      "3464 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR05 - Chunk # 2 de 3\n",
      "  - tempo de operação 20.1s\n",
      "3086 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR05 - Chunk # 3 de 3\n",
      "  - tempo de operação 6.6s\n",
      "2719 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR06 - Chunk # 1 de 2\n",
      "  - tempo de operação 14.2s\n",
      "3303 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR06 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.6s\n",
      "2785 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR07 - Chunk # 1 de 2\n",
      "  - tempo de operação 10.9s\n",
      "3293 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR07 - Chunk # 2 de 2\n",
      "  - tempo de operação 10.1s\n",
      "2801 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR08 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.6s\n",
      "3468 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR09 - Chunk # 1 de 1\n",
      "  - tempo de operação 14.6s\n",
      "3387 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR10 - Chunk # 1 de 8\n",
      "  - tempo de operação 9.5s\n",
      "3156 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR10 - Chunk # 2 de 8\n",
      "  - tempo de operação 40.5s\n",
      "3371 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR10 - Chunk # 3 de 8\n",
      "  - tempo de operação 12.3s\n",
      "3362 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR10 - Chunk # 4 de 8\n",
      "  - tempo de operação 10.2s\n",
      "3165 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR10 - Chunk # 5 de 8\n",
      "  - tempo de operação 13.4s\n",
      "3441 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR10 - Chunk # 6 de 8\n",
      "  - tempo de operação 13.8s\n",
      "3413 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR10 - Chunk # 7 de 8\n",
      "  - tempo de operação 7.6s\n",
      "2798 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR10 - Chunk # 8 de 8\n",
      "  - tempo de operação 13.9s\n",
      "3267 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR11 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.0s\n",
      "3151 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR12 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.7s\n",
      "2946 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR13 - Chunk # 1 de 2\n",
      "  - tempo de operação 12.7s\n",
      "3333 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR13 - Chunk # 2 de 2\n",
      "  - tempo de operação 5.7s\n",
      "2600 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR14 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.0s\n",
      "2641 tokens usados para extrair 6 relações\n",
      "doc_id EDUAR14 - Chunk # 2 de 2\n",
      "  - tempo de operação 93.9s\n",
      "9869 tokens usados para extrair 83 relações\n",
      "doc_id EDUAR15 - Chunk # 1 de 4\n",
      "  - tempo de operação 14.0s\n",
      "3371 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR15 - Chunk # 2 de 4\n",
      "  - tempo de operação 13.4s\n",
      "3456 tokens usados para extrair 12 relações\n",
      "doc_id EDUAR15 - Chunk # 3 de 4\n",
      "  - tempo de operação 14.2s\n",
      "3367 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR15 - Chunk # 4 de 4\n",
      "  - tempo de operação 6.2s\n",
      "2413 tokens usados para extrair 3 relações\n",
      "doc_id EDUAR16 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.5s\n",
      "2762 tokens usados para extrair 6 relações\n",
      "doc_id EDUAR17 - Chunk # 1 de 1\n",
      "  - tempo de operação 6.0s\n",
      "2552 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR18 - Chunk # 1 de 2\n",
      "  - tempo de operação 14.7s\n",
      "3213 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR18 - Chunk # 2 de 2\n",
      "  - tempo de operação 4.6s\n",
      "2459 tokens usados para extrair 3 relações\n",
      "doc_id EDUAR19 - Chunk # 1 de 1\n",
      "  - tempo de operação 5.2s\n",
      "2502 tokens usados para extrair 4 relações\n",
      "doc_id EDUAR20 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.8s\n",
      "3276 tokens usados para extrair 16 relações\n",
      "doc_id EDUAR21 - Chunk # 1 de 1\n",
      "  - tempo de operação 18.6s\n",
      "2931 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR22 - Chunk # 1 de 2\n",
      "  - tempo de operação 21.7s\n",
      "3519 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR22 - Chunk # 2 de 2\n",
      "  - tempo de operação 25.4s\n",
      "4206 tokens usados para extrair 23 relações\n",
      "doc_id EDUAR23 - Chunk # 1 de 1\n",
      "  - tempo de operação 4.9s\n",
      "2457 tokens usados para extrair 3 relações\n",
      "doc_id EDUAR24 - Chunk # 1 de 2\n",
      "  - tempo de operação 14.0s\n",
      "3418 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR24 - Chunk # 2 de 2\n",
      "  - tempo de operação 11.9s\n",
      "3143 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR25 - Chunk # 1 de 1\n",
      "  - tempo de operação 14.9s\n",
      "3432 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR26 - Chunk # 1 de 3\n",
      "  - tempo de operação 14.2s\n",
      "3563 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR26 - Chunk # 2 de 3\n",
      "  - tempo de operação 15.6s\n",
      "3601 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR26 - Chunk # 3 de 3\n",
      "  - tempo de operação 6.9s\n",
      "2563 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR27 - Chunk # 1 de 2\n",
      "  - tempo de operação 12.1s\n",
      "3315 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR27 - Chunk # 2 de 2\n",
      "  - tempo de operação 16.3s\n",
      "3441 tokens usados para extrair 16 relações\n",
      "doc_id EDUAR28 - Chunk # 1 de 2\n",
      "  - tempo de operação 11.3s\n",
      "3501 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR28 - Chunk # 2 de 2\n",
      "  - tempo de operação 13.0s\n",
      "3373 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR29 - Chunk # 1 de 5\n",
      "  - tempo de operação 19.5s\n",
      "3593 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR29 - Chunk # 2 de 5\n",
      "  - tempo de operação 15.3s\n",
      "3334 tokens usados para extrair 10 relações\n",
      "doc_id EDUAR29 - Chunk # 3 de 5\n",
      "  - tempo de operação 10.8s\n",
      "3092 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR29 - Chunk # 4 de 5\n",
      "  - tempo de operação 11.4s\n",
      "3329 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR29 - Chunk # 5 de 5\n",
      "  - tempo de operação 14.0s\n",
      "3175 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR30 - Chunk # 1 de 8\n",
      "  - tempo de operação 16.5s\n",
      "3523 tokens usados para extrair 14 relações\n",
      "doc_id EDUAR30 - Chunk # 2 de 8\n",
      "  - tempo de operação 15.2s\n",
      "3250 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR30 - Chunk # 3 de 8\n",
      "  - tempo de operação 14.4s\n",
      "3556 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR30 - Chunk # 4 de 8\n",
      "  - tempo de operação 16.2s\n",
      "3566 tokens usados para extrair 13 relações\n",
      "doc_id EDUAR30 - Chunk # 5 de 8\n",
      "  - tempo de operação 32.2s\n",
      "3979 tokens usados para extrair 16 relações\n",
      "doc_id EDUAR30 - Chunk # 6 de 8\n",
      "  - tempo de operação 16.0s\n",
      "3927 tokens usados para extrair 21 relações\n",
      "doc_id EDUAR30 - Chunk # 7 de 8\n",
      "  - tempo de operação 18.2s\n",
      "3856 tokens usados para extrair 18 relações\n",
      "doc_id EDUAR30 - Chunk # 8 de 8\n",
      "  - tempo de operação 6.6s\n",
      "2870 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR31 - Chunk # 1 de 3\n",
      "  - tempo de operação 12.8s\n",
      "3274 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR31 - Chunk # 2 de 3\n",
      "  - tempo de operação 8.7s\n",
      "3003 tokens usados para extrair 6 relações\n",
      "doc_id EDUAR31 - Chunk # 3 de 3\n",
      "  - tempo de operação 12.5s\n",
      "3315 tokens usados para extrair 14 relações\n",
      "doc_id EDUAR32 - Chunk # 1 de 12\n",
      "  - tempo de operação 9.8s\n",
      "3192 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR32 - Chunk # 2 de 12\n",
      "  - tempo de operação 27.8s\n",
      "4227 tokens usados para extrair 30 relações\n",
      "doc_id EDUAR32 - Chunk # 3 de 12\n",
      "  - tempo de operação 16.3s\n",
      "3614 tokens usados para extrair 19 relações\n",
      "doc_id EDUAR32 - Chunk # 4 de 12\n",
      "  - tempo de operação 26.4s\n",
      "3585 tokens usados para extrair 19 relações\n",
      "doc_id EDUAR32 - Chunk # 5 de 12\n",
      "  - tempo de operação 36.9s\n",
      "4031 tokens usados para extrair 26 relações\n",
      "doc_id EDUAR32 - Chunk # 6 de 12\n",
      "  - tempo de operação 28.5s\n",
      "3687 tokens usados para extrair 17 relações\n",
      "doc_id EDUAR32 - Chunk # 7 de 12\n",
      "  - tempo de operação 25.9s\n",
      "3484 tokens usados para extrair 16 relações\n",
      "doc_id EDUAR32 - Chunk # 8 de 12\n",
      "  - tempo de operação 12.5s\n",
      "2835 tokens usados para extrair 7 relações\n",
      "doc_id EDUAR32 - Chunk # 9 de 12\n",
      "  - tempo de operação 17.3s\n",
      "3653 tokens usados para extrair 20 relações\n",
      "doc_id EDUAR32 - Chunk # 10 de 12\n",
      "  - tempo de operação 11.0s\n",
      "3056 tokens usados para extrair 11 relações\n",
      "doc_id EDUAR32 - Chunk # 11 de 12\n",
      "  - tempo de operação 12.8s\n",
      "3332 tokens usados para extrair 15 relações\n",
      "doc_id EDUAR32 - Chunk # 12 de 12\n",
      "  - tempo de operação 24.4s\n",
      "3383 tokens usados para extrair 14 relações\n",
      "doc_id EDUAR33 - Chunk # 1 de 7\n",
      "  - tempo de operação 5.1s\n",
      "2752 tokens usados para extrair 5 relações\n",
      "doc_id EDUAR33 - Chunk # 2 de 7\n",
      "  - tempo de operação 32.4s\n",
      "3772 tokens usados para extrair 23 relações\n",
      "doc_id EDUAR33 - Chunk # 3 de 7\n",
      "  - tempo de operação 14.6s\n",
      "2991 tokens usados para extrair 9 relações\n",
      "doc_id EDUAR33 - Chunk # 4 de 7\n",
      "  - tempo de operação 21.7s\n",
      "3701 tokens usados para extrair 23 relações\n",
      "doc_id EDUAR33 - Chunk # 5 de 7\n",
      "  - tempo de operação 18.9s\n",
      "3909 tokens usados para extrair 25 relações\n",
      "doc_id EDUAR33 - Chunk # 6 de 7\n",
      "  - tempo de operação 16.6s\n",
      "3681 tokens usados para extrair 19 relações\n",
      "doc_id EDUAR33 - Chunk # 7 de 7\n",
      "  - tempo de operação 8.9s\n",
      "2968 tokens usados para extrair 8 relações\n",
      "doc_id EDUAR34 - Chunk # 1 de 1\n",
      "  - tempo de operação 8.0s\n",
      "2856 tokens usados para extrair 9 relações\n",
      "doc_id MARIA00 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.9s\n",
      "3269 tokens usados para extrair 12 relações\n",
      "doc_id MARIA00 - Chunk # 2 de 2\n",
      "  - tempo de operação 22.3s\n",
      "3488 tokens usados para extrair 17 relações\n",
      "doc_id MARIA01 - Chunk # 1 de 3\n",
      "  - tempo de operação 25.3s\n",
      "3434 tokens usados para extrair 13 relações\n",
      "doc_id MARIA01 - Chunk # 2 de 3\n",
      "  - tempo de operação 9.7s\n",
      "3206 tokens usados para extrair 9 relações\n",
      "doc_id MARIA01 - Chunk # 3 de 3\n",
      "  - tempo de operação 12.8s\n",
      "3274 tokens usados para extrair 13 relações\n",
      "doc_id MARIA02 - Chunk # 1 de 3\n",
      "  - tempo de operação 11.4s\n",
      "3299 tokens usados para extrair 14 relações\n",
      "doc_id MARIA02 - Chunk # 2 de 3\n",
      "  - tempo de operação 9.1s\n",
      "3117 tokens usados para extrair 9 relações\n",
      "doc_id MARIA02 - Chunk # 3 de 3\n",
      "  - tempo de operação 7.6s\n",
      "2868 tokens usados para extrair 8 relações\n",
      "doc_id MARIA03 - Chunk # 1 de 6\n",
      "  - tempo de operação 11.3s\n",
      "3336 tokens usados para extrair 11 relações\n",
      "doc_id MARIA03 - Chunk # 2 de 6\n",
      "  - tempo de operação 12.0s\n",
      "3297 tokens usados para extrair 14 relações\n",
      "doc_id MARIA03 - Chunk # 3 de 6\n",
      "  - tempo de operação 11.5s\n",
      "3282 tokens usados para extrair 12 relações\n",
      "doc_id MARIA03 - Chunk # 4 de 6\n",
      "  - tempo de operação 13.4s\n",
      "3520 tokens usados para extrair 17 relações\n",
      "doc_id MARIA03 - Chunk # 5 de 6\n",
      "  - tempo de operação 8.9s\n",
      "3038 tokens usados para extrair 11 relações\n",
      "doc_id MARIA03 - Chunk # 6 de 6\n",
      "  - tempo de operação 10.8s\n",
      "3357 tokens usados para extrair 12 relações\n",
      "doc_id MARIA04 - Chunk # 1 de 3\n",
      "  - tempo de operação 9.9s\n",
      "3304 tokens usados para extrair 12 relações\n",
      "doc_id MARIA04 - Chunk # 2 de 3\n",
      "  - tempo de operação 7.1s\n",
      "3083 tokens usados para extrair 8 relações\n",
      "doc_id MARIA04 - Chunk # 3 de 3\n",
      "  - tempo de operação 7.5s\n",
      "2754 tokens usados para extrair 8 relações\n",
      "doc_id MARIA05 - Chunk # 1 de 2\n",
      "  - tempo de operação 10.2s\n",
      "3167 tokens usados para extrair 10 relações\n",
      "doc_id MARIA05 - Chunk # 2 de 2\n",
      "  - tempo de operação 10.0s\n",
      "3117 tokens usados para extrair 10 relações\n",
      "doc_id MARIA06 - Chunk # 1 de 5\n",
      "  - tempo de operação 18.0s\n",
      "3578 tokens usados para extrair 19 relações\n",
      "doc_id MARIA06 - Chunk # 2 de 5\n",
      "  - tempo de operação 6.5s\n",
      "2823 tokens usados para extrair 7 relações\n",
      "doc_id MARIA06 - Chunk # 3 de 5\n",
      "  - tempo de operação 7.3s\n",
      "3019 tokens usados para extrair 6 relações\n",
      "doc_id MARIA06 - Chunk # 4 de 5\n",
      "  - tempo de operação 12.1s\n",
      "3378 tokens usados para extrair 13 relações\n",
      "doc_id MARIA06 - Chunk # 5 de 5\n",
      "  - tempo de operação 8.9s\n",
      "3100 tokens usados para extrair 12 relações\n",
      "doc_id MARIA07 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.2s\n",
      "3224 tokens usados para extrair 12 relações\n",
      "doc_id MARIA08 - Chunk # 1 de 4\n",
      "  - tempo de operação 10.9s\n",
      "3384 tokens usados para extrair 15 relações\n",
      "doc_id MARIA08 - Chunk # 2 de 4\n",
      "  - tempo de operação 7.1s\n",
      "3039 tokens usados para extrair 6 relações\n",
      "doc_id MARIA08 - Chunk # 3 de 4\n",
      "  - tempo de operação 17.0s\n",
      "3670 tokens usados para extrair 18 relações\n",
      "doc_id MARIA08 - Chunk # 4 de 4\n",
      "  - tempo de operação 11.6s\n",
      "2877 tokens usados para extrair 7 relações\n",
      "doc_id MARIA09 - Chunk # 1 de 3\n",
      "  - tempo de operação 9.8s\n",
      "3052 tokens usados para extrair 8 relações\n",
      "doc_id MARIA09 - Chunk # 2 de 3\n",
      "  - tempo de operação 14.2s\n",
      "3361 tokens usados para extrair 9 relações\n",
      "doc_id MARIA09 - Chunk # 3 de 3\n",
      "  - tempo de operação 6.4s\n",
      "2667 tokens usados para extrair 6 relações\n",
      "doc_id MARIA10 - Chunk # 1 de 1\n",
      "  - tempo de operação 7.3s\n",
      "3066 tokens usados para extrair 12 relações\n",
      "doc_id MARIA11 - Chunk # 1 de 2\n",
      "  - tempo de operação 11.4s\n",
      "3318 tokens usados para extrair 11 relações\n",
      "doc_id MARIA11 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.2s\n",
      "2673 tokens usados para extrair 5 relações\n",
      "doc_id MARIA12 - Chunk # 1 de 1\n",
      "  - tempo de operação 6.2s\n",
      "2754 tokens usados para extrair 7 relações\n",
      "doc_id CRIST00 - Chunk # 1 de 4\n",
      "  - tempo de operação 8.4s\n",
      "3051 tokens usados para extrair 8 relações\n",
      "doc_id CRIST00 - Chunk # 2 de 4\n",
      "  - tempo de operação 12.9s\n",
      "3556 tokens usados para extrair 18 relações\n",
      "doc_id CRIST00 - Chunk # 3 de 4\n",
      "  - tempo de operação 9.9s\n",
      "3229 tokens usados para extrair 10 relações\n",
      "doc_id CRIST00 - Chunk # 4 de 4\n",
      "  - tempo de operação 3.4s\n",
      "2475 tokens usados para extrair 3 relações\n",
      "doc_id CRIST01 - Chunk # 1 de 9\n",
      "  - tempo de operação 12.8s\n",
      "3103 tokens usados para extrair 11 relações\n",
      "doc_id CRIST01 - Chunk # 2 de 9\n",
      "  - tempo de operação 10.5s\n",
      "3247 tokens usados para extrair 11 relações\n",
      "doc_id CRIST01 - Chunk # 3 de 9\n",
      "  - tempo de operação 22.5s\n",
      "3175 tokens usados para extrair 10 relações\n",
      "doc_id CRIST01 - Chunk # 4 de 9\n",
      "  - tempo de operação 12.0s\n",
      "3398 tokens usados para extrair 12 relações\n",
      "doc_id CRIST01 - Chunk # 5 de 9\n",
      "  - tempo de operação 10.3s\n",
      "3205 tokens usados para extrair 9 relações\n",
      "doc_id CRIST01 - Chunk # 6 de 9\n",
      "  - tempo de operação 11.8s\n",
      "3444 tokens usados para extrair 14 relações\n",
      "doc_id CRIST01 - Chunk # 7 de 9\n",
      "  - tempo de operação 11.1s\n",
      "3367 tokens usados para extrair 12 relações\n",
      "doc_id CRIST01 - Chunk # 8 de 9\n",
      "  - tempo de operação 7.9s\n",
      "3070 tokens usados para extrair 7 relações\n",
      "doc_id CRIST01 - Chunk # 9 de 9\n",
      "  - tempo de operação 4.4s\n",
      "2629 tokens usados para extrair 5 relações\n",
      "doc_id CRIST02 - Chunk # 1 de 5\n",
      "  - tempo de operação 9.5s\n",
      "3216 tokens usados para extrair 11 relações\n",
      "doc_id CRIST02 - Chunk # 2 de 5\n",
      "  - tempo de operação 10.4s\n",
      "3271 tokens usados para extrair 11 relações\n",
      "doc_id CRIST02 - Chunk # 3 de 5\n",
      "  - tempo de operação 15.1s\n",
      "3638 tokens usados para extrair 17 relações\n",
      "doc_id CRIST02 - Chunk # 4 de 5\n",
      "  - tempo de operação 12.8s\n",
      "3506 tokens usados para extrair 14 relações\n",
      "doc_id CRIST02 - Chunk # 5 de 5\n",
      "  - tempo de operação 7.4s\n",
      "2764 tokens usados para extrair 8 relações\n",
      "doc_id CRIST03 - Chunk # 1 de 5\n",
      "  - tempo de operação 11.3s\n",
      "3357 tokens usados para extrair 15 relações\n",
      "doc_id CRIST03 - Chunk # 2 de 5\n",
      "  - tempo de operação 12.0s\n",
      "3464 tokens usados para extrair 13 relações\n",
      "doc_id CRIST03 - Chunk # 3 de 5\n",
      "  - tempo de operação 17.1s\n",
      "3657 tokens usados para extrair 15 relações\n",
      "doc_id CRIST03 - Chunk # 4 de 5\n",
      "  - tempo de operação 9.7s\n",
      "3418 tokens usados para extrair 13 relações\n",
      "doc_id CRIST03 - Chunk # 5 de 5\n",
      "  - tempo de operação 10.2s\n",
      "3301 tokens usados para extrair 15 relações\n",
      "doc_id CRIST04 - Chunk # 1 de 5\n",
      "  - tempo de operação 12.3s\n",
      "3248 tokens usados para extrair 13 relações\n",
      "doc_id CRIST04 - Chunk # 2 de 5\n",
      "  - tempo de operação 10.7s\n",
      "3232 tokens usados para extrair 11 relações\n",
      "doc_id CRIST04 - Chunk # 3 de 5\n",
      "  - tempo de operação 16.2s\n",
      "3100 tokens usados para extrair 9 relações\n",
      "doc_id CRIST04 - Chunk # 4 de 5\n",
      "  - tempo de operação 11.7s\n",
      "3209 tokens usados para extrair 10 relações\n",
      "doc_id CRIST04 - Chunk # 5 de 5\n",
      "  - tempo de operação 8.4s\n",
      "2884 tokens usados para extrair 9 relações\n",
      "doc_id CRIST05 - Chunk # 1 de 5\n",
      "  - tempo de operação 15.7s\n",
      "3580 tokens usados para extrair 19 relações\n",
      "doc_id CRIST05 - Chunk # 2 de 5\n",
      "  - tempo de operação 9.6s\n",
      "3121 tokens usados para extrair 9 relações\n",
      "doc_id CRIST05 - Chunk # 3 de 5\n",
      "  - tempo de operação 11.7s\n",
      "3412 tokens usados para extrair 13 relações\n",
      "doc_id CRIST05 - Chunk # 4 de 5\n",
      "  - tempo de operação 18.4s\n",
      "3304 tokens usados para extrair 10 relações\n",
      "doc_id CRIST05 - Chunk # 5 de 5\n",
      "  - tempo de operação 14.4s\n",
      "3151 tokens usados para extrair 11 relações\n",
      "doc_id CRIST06 - Chunk # 1 de 5\n",
      "  - tempo de operação 16.3s\n",
      "3428 tokens usados para extrair 15 relações\n",
      "doc_id CRIST06 - Chunk # 2 de 5\n",
      "  - tempo de operação 20.8s\n",
      "3400 tokens usados para extrair 12 relações\n",
      "doc_id CRIST06 - Chunk # 3 de 5\n",
      "  - tempo de operação 18.7s\n",
      "3210 tokens usados para extrair 11 relações\n",
      "doc_id CRIST06 - Chunk # 4 de 5\n",
      "  - tempo de operação 11.1s\n",
      "3157 tokens usados para extrair 8 relações\n",
      "doc_id CRIST06 - Chunk # 5 de 5\n",
      "  - tempo de operação 5.1s\n",
      "2632 tokens usados para extrair 5 relações\n",
      "doc_id CRIST07 - Chunk # 1 de 4\n",
      "  - tempo de operação 24.0s\n",
      "3482 tokens usados para extrair 17 relações\n",
      "doc_id CRIST07 - Chunk # 2 de 4\n",
      "  - tempo de operação 10.9s\n",
      "3258 tokens usados para extrair 10 relações\n",
      "doc_id CRIST07 - Chunk # 3 de 4\n",
      "  - tempo de operação 15.9s\n",
      "3223 tokens usados para extrair 10 relações\n",
      "doc_id CRIST07 - Chunk # 4 de 4\n",
      "  - tempo de operação 15.6s\n",
      "2957 tokens usados para extrair 9 relações\n",
      "doc_id CRIST08 - Chunk # 1 de 4\n",
      "  - tempo de operação 14.7s\n",
      "3439 tokens usados para extrair 15 relações\n",
      "doc_id CRIST08 - Chunk # 2 de 4\n",
      "  - tempo de operação 14.9s\n",
      "3386 tokens usados para extrair 14 relações\n",
      "doc_id CRIST08 - Chunk # 3 de 4\n",
      "  - tempo de operação 19.4s\n",
      "3217 tokens usados para extrair 10 relações\n",
      "doc_id CRIST08 - Chunk # 4 de 4\n",
      "  - tempo de operação 13.8s\n",
      "3169 tokens usados para extrair 9 relações\n",
      "doc_id CRIST09 - Chunk # 1 de 3\n",
      "  - tempo de operação 17.6s\n",
      "3382 tokens usados para extrair 12 relações\n",
      "doc_id CRIST09 - Chunk # 2 de 3\n",
      "  - tempo de operação 14.4s\n",
      "3534 tokens usados para extrair 15 relações\n",
      "doc_id CRIST09 - Chunk # 3 de 3\n",
      "  - tempo de operação 8.0s\n",
      "3106 tokens usados para extrair 8 relações\n",
      "doc_id CRIST10 - Chunk # 1 de 5\n",
      "  - tempo de operação 20.1s\n",
      "3367 tokens usados para extrair 15 relações\n",
      "doc_id CRIST10 - Chunk # 2 de 5\n",
      "  - tempo de operação 19.5s\n",
      "3343 tokens usados para extrair 13 relações\n",
      "doc_id CRIST10 - Chunk # 3 de 5\n",
      "  - tempo de operação 18.4s\n",
      "3507 tokens usados para extrair 15 relações\n",
      "doc_id CRIST10 - Chunk # 4 de 5\n",
      "  - tempo de operação 12.4s\n",
      "3431 tokens usados para extrair 12 relações\n",
      "doc_id CRIST10 - Chunk # 5 de 5\n",
      "  - tempo de operação 11.9s\n",
      "3360 tokens usados para extrair 13 relações\n",
      "doc_id CRIST11 - Chunk # 1 de 5\n",
      "  - tempo de operação 12.5s\n",
      "3445 tokens usados para extrair 15 relações\n",
      "doc_id CRIST11 - Chunk # 2 de 5\n",
      "  - tempo de operação 10.0s\n",
      "3083 tokens usados para extrair 8 relações\n",
      "doc_id CRIST11 - Chunk # 3 de 5\n",
      "  - tempo de operação 9.7s\n",
      "3212 tokens usados para extrair 9 relações\n",
      "doc_id CRIST11 - Chunk # 4 de 5\n",
      "  - tempo de operação 11.0s\n",
      "3266 tokens usados para extrair 10 relações\n",
      "doc_id CRIST11 - Chunk # 5 de 5\n",
      "  - tempo de operação 8.2s\n",
      "2726 tokens usados para extrair 9 relações\n",
      "doc_id CRIST12 - Chunk # 1 de 4\n",
      "  - tempo de operação 11.1s\n",
      "3303 tokens usados para extrair 14 relações\n",
      "doc_id CRIST12 - Chunk # 2 de 4\n",
      "  - tempo de operação 13.4s\n",
      "3517 tokens usados para extrair 13 relações\n",
      "doc_id CRIST12 - Chunk # 3 de 4\n",
      "  - tempo de operação 9.6s\n",
      "3261 tokens usados para extrair 10 relações\n",
      "doc_id CRIST12 - Chunk # 4 de 4\n",
      "  - tempo de operação 8.2s\n",
      "3075 tokens usados para extrair 8 relações\n",
      "doc_id CRIST13 - Chunk # 1 de 5\n",
      "  - tempo de operação 10.6s\n",
      "3162 tokens usados para extrair 11 relações\n",
      "doc_id CRIST13 - Chunk # 2 de 5\n",
      "  - tempo de operação 14.0s\n",
      "3248 tokens usados para extrair 11 relações\n",
      "doc_id CRIST13 - Chunk # 3 de 5\n",
      "  - tempo de operação 20.5s\n",
      "3388 tokens usados para extrair 12 relações\n",
      "doc_id CRIST13 - Chunk # 4 de 5\n",
      "  - tempo de operação 10.6s\n",
      "3268 tokens usados para extrair 11 relações\n",
      "doc_id CRIST13 - Chunk # 5 de 5\n",
      "  - tempo de operação 5.0s\n",
      "2594 tokens usados para extrair 5 relações\n",
      "doc_id CRIST14 - Chunk # 1 de 3\n",
      "  - tempo de operação 10.6s\n",
      "3239 tokens usados para extrair 11 relações\n",
      "doc_id CRIST14 - Chunk # 2 de 3\n",
      "  - tempo de operação 16.7s\n",
      "3332 tokens usados para extrair 12 relações\n",
      "doc_id CRIST14 - Chunk # 3 de 3\n",
      "  - tempo de operação 5.1s\n",
      "2740 tokens usados para extrair 5 relações\n",
      "doc_id CRIST15 - Chunk # 1 de 3\n",
      "  - tempo de operação 13.3s\n",
      "3345 tokens usados para extrair 15 relações\n",
      "doc_id CRIST15 - Chunk # 2 de 3\n",
      "  - tempo de operação 6.5s\n",
      "2865 tokens usados para extrair 5 relações\n",
      "doc_id CRIST15 - Chunk # 3 de 3\n",
      "  - tempo de operação 12.1s\n",
      "3424 tokens usados para extrair 15 relações\n",
      "doc_id CRIST16 - Chunk # 1 de 2\n",
      "  - tempo de operação 13.2s\n",
      "3368 tokens usados para extrair 14 relações\n",
      "doc_id CRIST16 - Chunk # 2 de 2\n",
      "  - tempo de operação 4.9s\n",
      "2563 tokens usados para extrair 5 relações\n",
      "doc_id NEY L00 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.4s\n",
      "3141 tokens usados para extrair 10 relações\n",
      "doc_id NEY L00 - Chunk # 2 de 2\n",
      "  - tempo de operação 10.1s\n",
      "2927 tokens usados para extrair 9 relações\n",
      "doc_id NEY L01 - Chunk # 1 de 3\n",
      "  - tempo de operação 20.1s\n",
      "3691 tokens usados para extrair 17 relações\n",
      "doc_id NEY L01 - Chunk # 2 de 3\n",
      "  - tempo de operação 0.8s\n",
      "2327 tokens usados para extrair 0 relações\n",
      "doc_id NEY L01 - Chunk # 3 de 3\n",
      "  - tempo de operação 13.8s\n",
      "3710 tokens usados para extrair 13 relações\n",
      "doc_id NEY L02 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.0s\n",
      "2780 tokens usados para extrair 7 relações\n",
      "doc_id NEY L03 - Chunk # 1 de 1\n",
      "  - tempo de operação 7.8s\n",
      "2919 tokens usados para extrair 7 relações\n",
      "doc_id NEY L04 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.4s\n",
      "2922 tokens usados para extrair 7 relações\n",
      "doc_id NEY L05 - Chunk # 1 de 1\n",
      "  - tempo de operação 14.0s\n",
      "3259 tokens usados para extrair 10 relações\n",
      "doc_id NEY L06 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.7s\n",
      "2979 tokens usados para extrair 8 relações\n",
      "doc_id NEY L07 - Chunk # 1 de 2\n",
      "  - tempo de operação 13.9s\n",
      "3410 tokens usados para extrair 15 relações\n",
      "doc_id NEY L07 - Chunk # 2 de 2\n",
      "  - tempo de operação 2.8s\n",
      "2359 tokens usados para extrair 3 relações\n",
      "doc_id NEY L08 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.2s\n",
      "3133 tokens usados para extrair 13 relações\n",
      "doc_id NEY L09 - Chunk # 1 de 1\n",
      "  - tempo de operação 13.8s\n",
      "2895 tokens usados para extrair 7 relações\n",
      "doc_id NEY L10 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.9s\n",
      "3220 tokens usados para extrair 11 relações\n",
      "doc_id NEY L10 - Chunk # 2 de 2\n",
      "  - tempo de operação 7.1s\n",
      "2806 tokens usados para extrair 6 relações\n",
      "doc_id NEY L11 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.9s\n",
      "3466 tokens usados para extrair 15 relações\n",
      "doc_id NEY L12 - Chunk # 1 de 4\n",
      "  - tempo de operação 10.0s\n",
      "3248 tokens usados para extrair 11 relações\n",
      "doc_id NEY L12 - Chunk # 2 de 4\n",
      "  - tempo de operação 12.1s\n",
      "3307 tokens usados para extrair 11 relações\n",
      "doc_id NEY L12 - Chunk # 3 de 4\n",
      "  - tempo de operação 9.4s\n",
      "3199 tokens usados para extrair 8 relações\n",
      "doc_id NEY L12 - Chunk # 4 de 4\n",
      "  - tempo de operação 16.0s\n",
      "3304 tokens usados para extrair 13 relações\n",
      "doc_id NEY L13 - Chunk # 1 de 2\n",
      "  - tempo de operação 12.6s\n",
      "3426 tokens usados para extrair 12 relações\n",
      "doc_id NEY L13 - Chunk # 2 de 2\n",
      "  - tempo de operação 3.8s\n",
      "2496 tokens usados para extrair 5 relações\n",
      "doc_id NEY L14 - Chunk # 1 de 5\n",
      "  - tempo de operação 20.3s\n",
      "3753 tokens usados para extrair 21 relações\n",
      "doc_id NEY L14 - Chunk # 2 de 5\n",
      "  - tempo de operação 18.8s\n",
      "3504 tokens usados para extrair 14 relações\n",
      "doc_id NEY L14 - Chunk # 3 de 5\n",
      "  - tempo de operação 15.8s\n",
      "3458 tokens usados para extrair 14 relações\n",
      "doc_id NEY L14 - Chunk # 4 de 5\n",
      "  - tempo de operação 13.1s\n",
      "3334 tokens usados para extrair 12 relações\n",
      "doc_id NEY L14 - Chunk # 5 de 5\n",
      "  - tempo de operação 12.0s\n",
      "3251 tokens usados para extrair 12 relações\n",
      "doc_id NEY L15 - Chunk # 1 de 2\n",
      "  - tempo de operação 14.1s\n",
      "3502 tokens usados para extrair 13 relações\n",
      "doc_id NEY L15 - Chunk # 2 de 2\n",
      "  - tempo de operação 15.5s\n",
      "3538 tokens usados para extrair 19 relações\n",
      "doc_id NEY L16 - Chunk # 1 de 4\n",
      "  - tempo de operação 10.7s\n",
      "3094 tokens usados para extrair 8 relações\n",
      "doc_id NEY L16 - Chunk # 2 de 4\n",
      "  - tempo de operação 14.3s\n",
      "3358 tokens usados para extrair 10 relações\n",
      "doc_id NEY L16 - Chunk # 3 de 4\n",
      "  - tempo de operação 11.4s\n",
      "3385 tokens usados para extrair 11 relações\n",
      "doc_id NEY L16 - Chunk # 4 de 4\n",
      "  - tempo de operação 6.5s\n",
      "2734 tokens usados para extrair 6 relações\n",
      "doc_id NEY L17 - Chunk # 1 de 2\n",
      "  - tempo de operação 13.6s\n",
      "3430 tokens usados para extrair 14 relações\n",
      "doc_id NEY L17 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.9s\n",
      "2674 tokens usados para extrair 6 relações\n",
      "doc_id NEY L18 - Chunk # 1 de 2\n",
      "  - tempo de operação 18.3s\n",
      "3607 tokens usados para extrair 17 relações\n",
      "doc_id NEY L18 - Chunk # 2 de 2\n",
      "  - tempo de operação 10.1s\n",
      "2994 tokens usados para extrair 8 relações\n",
      "doc_id NEY L19 - Chunk # 1 de 1\n",
      "  - tempo de operação 19.7s\n",
      "3464 tokens usados para extrair 17 relações\n",
      "doc_id NEY L20 - Chunk # 1 de 3\n",
      "  - tempo de operação 16.0s\n",
      "3565 tokens usados para extrair 17 relações\n",
      "doc_id NEY L20 - Chunk # 2 de 3\n",
      "  - tempo de operação 15.4s\n",
      "3440 tokens usados para extrair 13 relações\n",
      "doc_id NEY L20 - Chunk # 3 de 3\n",
      "  - tempo de operação 11.2s\n",
      "2859 tokens usados para extrair 6 relações\n",
      "doc_id NEY L21 - Chunk # 1 de 2\n",
      "  - tempo de operação 17.5s\n",
      "3526 tokens usados para extrair 15 relações\n",
      "doc_id NEY L21 - Chunk # 2 de 2\n",
      "  - tempo de operação 7.8s\n",
      "2761 tokens usados para extrair 8 relações\n",
      "doc_id NEY L22 - Chunk # 1 de 2\n",
      "  - tempo de operação 15.2s\n",
      "3547 tokens usados para extrair 16 relações\n",
      "doc_id NEY L22 - Chunk # 2 de 2\n",
      "  - tempo de operação 5.9s\n",
      "2573 tokens usados para extrair 6 relações\n",
      "doc_id LUCIA00 - Chunk # 1 de 7\n",
      "  - tempo de operação 15.4s\n",
      "3373 tokens usados para extrair 13 relações\n",
      "doc_id LUCIA00 - Chunk # 2 de 7\n",
      "  - tempo de operação 12.8s\n",
      "3372 tokens usados para extrair 13 relações\n",
      "doc_id LUCIA00 - Chunk # 3 de 7\n",
      "  - tempo de operação 10.4s\n",
      "3224 tokens usados para extrair 11 relações\n",
      "doc_id LUCIA00 - Chunk # 4 de 7\n",
      "  - tempo de operação 13.1s\n",
      "3338 tokens usados para extrair 9 relações\n",
      "doc_id LUCIA00 - Chunk # 5 de 7\n",
      "  - tempo de operação 7.5s\n",
      "3121 tokens usados para extrair 5 relações\n",
      "doc_id LUCIA00 - Chunk # 6 de 7\n",
      "  - tempo de operação 11.0s\n",
      "3296 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA00 - Chunk # 7 de 7\n",
      "  - tempo de operação 3.8s\n",
      "2455 tokens usados para extrair 3 relações\n",
      "doc_id LUCIA01 - Chunk # 1 de 4\n",
      "  - tempo de operação 6.1s\n",
      "2952 tokens usados para extrair 7 relações\n",
      "doc_id LUCIA01 - Chunk # 2 de 4\n",
      "  - tempo de operação 10.5s\n",
      "3207 tokens usados para extrair 11 relações\n",
      "doc_id LUCIA01 - Chunk # 3 de 4\n",
      "  - tempo de operação 11.6s\n",
      "3061 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA01 - Chunk # 4 de 4\n",
      "  - tempo de operação 9.7s\n",
      "3234 tokens usados para extrair 9 relações\n",
      "doc_id LUCIA02 - Chunk # 1 de 2\n",
      "  - tempo de operação 12.5s\n",
      "3192 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA02 - Chunk # 2 de 2\n",
      "  - tempo de operação 12.1s\n",
      "2760 tokens usados para extrair 5 relações\n",
      "doc_id LUCIA03 - Chunk # 1 de 3\n",
      "  - tempo de operação 13.0s\n",
      "3221 tokens usados para extrair 13 relações\n",
      "doc_id LUCIA03 - Chunk # 2 de 3\n",
      "  - tempo de operação 14.0s\n",
      "3386 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA03 - Chunk # 3 de 3\n",
      "  - tempo de operação 3.2s\n",
      "2363 tokens usados para extrair 3 relações\n",
      "doc_id LUCIA04 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.9s\n",
      "2420 tokens usados para extrair 3 relações\n",
      "doc_id LUCIA04 - Chunk # 2 de 2\n",
      "  - tempo de operação 26.8s\n",
      "4389 tokens usados para extrair 23 relações\n",
      "doc_id LUCIA05 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.6s\n",
      "3011 tokens usados para extrair 8 relações\n",
      "doc_id LUCIA06 - Chunk # 1 de 1\n",
      "  - tempo de operação 22.8s\n",
      "3655 tokens usados para extrair 19 relações\n",
      "doc_id LUCIA07 - Chunk # 1 de 2\n",
      "  - tempo de operação 9.4s\n",
      "3259 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA07 - Chunk # 2 de 2\n",
      "  - tempo de operação 15.6s\n",
      "3393 tokens usados para extrair 10 relações\n",
      "doc_id LUCIA08 - Chunk # 1 de 1\n",
      "  - tempo de operação 13.3s\n",
      "3107 tokens usados para extrair 9 relações\n",
      "doc_id LUCIA09 - Chunk # 1 de 1\n",
      "  - tempo de operação 27.5s\n",
      "3615 tokens usados para extrair 22 relações\n",
      "doc_id LUCIA10 - Chunk # 1 de 2\n",
      "  - tempo de operação 7.0s\n",
      "2719 tokens usados para extrair 5 relações\n",
      "doc_id LUCIA10 - Chunk # 2 de 2\n",
      "  - tempo de operação 25.5s\n",
      "3653 tokens usados para extrair 15 relações\n",
      "doc_id LUCIA11 - Chunk # 1 de 1\n",
      "  - tempo de operação 13.1s\n",
      "2981 tokens usados para extrair 14 relações\n",
      "doc_id LUCIA12 - Chunk # 1 de 1\n",
      "  - tempo de operação 3.9s\n",
      "2330 tokens usados para extrair 3 relações\n",
      "doc_id LUCIA13 - Chunk # 1 de 1\n",
      "  - tempo de operação 31.7s\n",
      "3777 tokens usados para extrair 20 relações\n",
      "doc_id LUCIA14 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.7s\n",
      "2858 tokens usados para extrair 11 relações\n",
      "doc_id LUCIA15 - Chunk # 1 de 1\n",
      "  - tempo de operação 12.5s\n",
      "3310 tokens usados para extrair 8 relações\n",
      "doc_id LUCIA16 - Chunk # 1 de 1\n",
      "  - tempo de operação 5.6s\n",
      "2390 tokens usados para extrair 3 relações\n",
      "doc_id LUCIA17 - Chunk # 1 de 2\n",
      "  - tempo de operação 19.3s\n",
      "3468 tokens usados para extrair 13 relações\n",
      "doc_id LUCIA17 - Chunk # 2 de 2\n",
      "  - tempo de operação 18.1s\n",
      "3639 tokens usados para extrair 18 relações\n",
      "doc_id LUCIA18 - Chunk # 1 de 1\n",
      "  - tempo de operação 27.1s\n",
      "3359 tokens usados para extrair 15 relações\n",
      "doc_id LUIZ 00 - Chunk # 1 de 1\n",
      "  - tempo de operação 20.3s\n",
      "3264 tokens usados para extrair 13 relações\n",
      "doc_id LUIZ 01 - Chunk # 1 de 2\n",
      "  - tempo de operação 18.5s\n",
      "3632 tokens usados para extrair 19 relações\n",
      "doc_id LUIZ 01 - Chunk # 2 de 2\n",
      "  - tempo de operação 29.4s\n",
      "3400 tokens usados para extrair 15 relações\n",
      "doc_id LUIZ 02 - Chunk # 1 de 2\n",
      "  - tempo de operação 23.5s\n",
      "3493 tokens usados para extrair 15 relações\n",
      "doc_id LUIZ 02 - Chunk # 2 de 2\n",
      "  - tempo de operação 3.9s\n",
      "2407 tokens usados para extrair 3 relações\n",
      "doc_id LUIZ 03 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.5s\n",
      "2802 tokens usados para extrair 9 relações\n",
      "doc_id LUIZ 04 - Chunk # 1 de 1\n",
      "  - tempo de operação 25.9s\n",
      "3945 tokens usados para extrair 23 relações\n",
      "doc_id LUIZ 05 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.9s\n",
      "3064 tokens usados para extrair 11 relações\n",
      "doc_id LUIZ 06 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.8s\n",
      "3113 tokens usados para extrair 12 relações\n",
      "doc_id LUIZ 07 - Chunk # 1 de 2\n",
      "  - tempo de operação 13.8s\n",
      "3426 tokens usados para extrair 16 relações\n",
      "doc_id LUIZ 07 - Chunk # 2 de 2\n",
      "  - tempo de operação 16.2s\n",
      "3385 tokens usados para extrair 12 relações\n",
      "doc_id LUIZ 08 - Chunk # 1 de 1\n",
      "  - tempo de operação 19.0s\n",
      "3468 tokens usados para extrair 17 relações\n",
      "doc_id LUIZ 09 - Chunk # 1 de 1\n",
      "  - tempo de operação 19.7s\n",
      "3721 tokens usados para extrair 21 relações\n",
      "doc_id LUIZ 10 - Chunk # 1 de 1\n",
      "  - tempo de operação 22.6s\n",
      "3727 tokens usados para extrair 23 relações\n",
      "doc_id LUIZ 11 - Chunk # 1 de 1\n",
      "  - tempo de operação 24.0s\n",
      "4091 tokens usados para extrair 27 relações\n",
      "doc_id LUIZ 12 - Chunk # 1 de 1\n",
      "  - tempo de operação 22.6s\n",
      "3713 tokens usados para extrair 21 relações\n",
      "doc_id LUIZ 13 - Chunk # 1 de 1\n",
      "  - tempo de operação 16.9s\n",
      "3401 tokens usados para extrair 17 relações\n",
      "doc_id LUIZ 14 - Chunk # 1 de 2\n",
      "  - tempo de operação 22.5s\n",
      "3780 tokens usados para extrair 23 relações\n",
      "doc_id LUIZ 14 - Chunk # 2 de 2\n",
      "  - tempo de operação 7.7s\n",
      "2706 tokens usados para extrair 5 relações\n",
      "doc_id LUIZ 15 - Chunk # 1 de 2\n",
      "  - tempo de operação 14.7s\n",
      "3356 tokens usados para extrair 12 relações\n",
      "doc_id LUIZ 15 - Chunk # 2 de 2\n",
      "  - tempo de operação 11.1s\n",
      "2939 tokens usados para extrair 7 relações\n",
      "doc_id LUIZ 16 - Chunk # 1 de 2\n",
      "  - tempo de operação 25.8s\n",
      "4173 tokens usados para extrair 28 relações\n",
      "doc_id LUIZ 16 - Chunk # 2 de 2\n",
      "  - tempo de operação 3.7s\n",
      "2410 tokens usados para extrair 3 relações\n",
      "doc_id LUIZ 17 - Chunk # 1 de 2\n",
      "  - tempo de operação 11.9s\n",
      "3443 tokens usados para extrair 13 relações\n",
      "doc_id LUIZ 17 - Chunk # 2 de 2\n",
      "  - tempo de operação 8.1s\n",
      "2736 tokens usados para extrair 7 relações\n",
      "doc_id LUIZ 18 - Chunk # 1 de 1\n",
      "  - tempo de operação 21.4s\n",
      "3624 tokens usados para extrair 19 relações\n",
      "doc_id ROBER00 - Chunk # 1 de 1\n",
      "  - tempo de operação 12.8s\n",
      "3229 tokens usados para extrair 15 relações\n",
      "doc_id ROBER01 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.8s\n",
      "3375 tokens usados para extrair 13 relações\n",
      "doc_id ROBER02 - Chunk # 1 de 2\n",
      "  - tempo de operação 19.0s\n",
      "3669 tokens usados para extrair 18 relações\n",
      "doc_id ROBER02 - Chunk # 2 de 2\n",
      "  - tempo de operação 6.3s\n",
      "2570 tokens usados para extrair 5 relações\n",
      "doc_id ROBER03 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.7s\n",
      "3126 tokens usados para extrair 12 relações\n",
      "doc_id ROBER04 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.3s\n",
      "3011 tokens usados para extrair 9 relações\n",
      "doc_id ROBER05 - Chunk # 1 de 1\n",
      "  - tempo de operação 23.1s\n",
      "4010 tokens usados para extrair 25 relações\n",
      "doc_id ROBER06 - Chunk # 1 de 1\n",
      "  - tempo de operação 13.7s\n",
      "3293 tokens usados para extrair 11 relações\n",
      "doc_id ROBER07 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.4s\n",
      "3000 tokens usados para extrair 7 relações\n",
      "doc_id ROBER08 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.0s\n",
      "3197 tokens usados para extrair 11 relações\n",
      "doc_id ROBER09 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.8s\n",
      "3028 tokens usados para extrair 10 relações\n",
      "doc_id ROBER10 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.7s\n",
      "3095 tokens usados para extrair 11 relações\n",
      "doc_id ROBER11 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.5s\n",
      "3157 tokens usados para extrair 10 relações\n",
      "doc_id ROBER12 - Chunk # 1 de 1\n",
      "  - tempo de operação 14.4s\n",
      "3356 tokens usados para extrair 15 relações\n",
      "doc_id ROBER13 - Chunk # 1 de 2\n",
      "  - tempo de operação 18.3s\n",
      "3693 tokens usados para extrair 19 relações\n",
      "doc_id ROBER13 - Chunk # 2 de 2\n",
      "  - tempo de operação 3.8s\n",
      "2339 tokens usados para extrair 3 relações\n",
      "doc_id ROBER14 - Chunk # 1 de 1\n",
      "  - tempo de operação 15.9s\n",
      "3509 tokens usados para extrair 17 relações\n",
      "doc_id ROBER15 - Chunk # 1 de 1\n",
      "  - tempo de operação 8.6s\n",
      "2750 tokens usados para extrair 8 relações\n",
      "doc_id ROBER16 - Chunk # 1 de 1\n",
      "  - tempo de operação 11.2s\n",
      "3123 tokens usados para extrair 12 relações\n",
      "doc_id SAMUE00 - Chunk # 1 de 8\n",
      "  - tempo de operação 15.7s\n",
      "3322 tokens usados para extrair 11 relações\n",
      "doc_id SAMUE00 - Chunk # 2 de 8\n",
      "  - tempo de operação 9.9s\n",
      "3104 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE00 - Chunk # 3 de 8\n",
      "  - tempo de operação 10.5s\n",
      "2913 tokens usados para extrair 10 relações\n",
      "doc_id SAMUE00 - Chunk # 4 de 8\n",
      "  - tempo de operação 20.6s\n",
      "3747 tokens usados para extrair 21 relações\n",
      "doc_id SAMUE00 - Chunk # 5 de 8\n",
      "  - tempo de operação 8.2s\n",
      "3176 tokens usados para extrair 8 relações\n",
      "doc_id SAMUE00 - Chunk # 6 de 8\n",
      "  - tempo de operação 7.3s\n",
      "3019 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE00 - Chunk # 7 de 8\n",
      "  - tempo de operação 6.7s\n",
      "3037 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE00 - Chunk # 8 de 8\n",
      "  - tempo de operação 16.3s\n",
      "3190 tokens usados para extrair 13 relações\n",
      "doc_id SAMUE01 - Chunk # 1 de 5\n",
      "  - tempo de operação 14.3s\n",
      "3425 tokens usados para extrair 14 relações\n",
      "doc_id SAMUE01 - Chunk # 2 de 5\n",
      "  - tempo de operação 10.3s\n",
      "3240 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE01 - Chunk # 3 de 5\n",
      "  - tempo de operação 15.6s\n",
      "3605 tokens usados para extrair 17 relações\n",
      "doc_id SAMUE01 - Chunk # 4 de 5\n",
      "  - tempo de operação 10.4s\n",
      "3138 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE01 - Chunk # 5 de 5\n",
      "  - tempo de operação 8.7s\n",
      "2936 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE02 - Chunk # 1 de 8\n",
      "  - tempo de operação 8.1s\n",
      "3011 tokens usados para extrair 8 relações\n",
      "doc_id SAMUE02 - Chunk # 2 de 8\n",
      "  - tempo de operação 18.9s\n",
      "3752 tokens usados para extrair 18 relações\n",
      "doc_id SAMUE02 - Chunk # 3 de 8\n",
      "  - tempo de operação 4.7s\n",
      "2838 tokens usados para extrair 5 relações\n",
      "doc_id SAMUE02 - Chunk # 4 de 8\n",
      "  - tempo de operação 11.1s\n",
      "3193 tokens usados para extrair 13 relações\n",
      "doc_id SAMUE02 - Chunk # 5 de 8\n",
      "  - tempo de operação 12.1s\n",
      "3200 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE02 - Chunk # 6 de 8\n",
      "  - tempo de operação 16.1s\n",
      "3226 tokens usados para extrair 8 relações\n",
      "doc_id SAMUE02 - Chunk # 7 de 8\n",
      "  - tempo de operação 29.7s\n",
      "3756 tokens usados para extrair 21 relações\n",
      "doc_id SAMUE02 - Chunk # 8 de 8\n",
      "  - tempo de operação 36.7s\n",
      "4353 tokens usados para extrair 31 relações\n",
      "doc_id SAMUE03 - Chunk # 1 de 5\n",
      "  - tempo de operação 8.1s\n",
      "3069 tokens usados para extrair 10 relações\n",
      "doc_id SAMUE03 - Chunk # 2 de 5\n",
      "  - tempo de operação 6.7s\n",
      "2934 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE03 - Chunk # 3 de 5\n",
      "  - tempo de operação 22.7s\n",
      "3472 tokens usados para extrair 14 relações\n",
      "doc_id SAMUE03 - Chunk # 4 de 5\n",
      "  - tempo de operação 12.4s\n",
      "3205 tokens usados para extrair 12 relações\n",
      "doc_id SAMUE03 - Chunk # 5 de 5\n",
      "  - tempo de operação 34.3s\n",
      "4681 tokens usados para extrair 40 relações\n",
      "doc_id SAMUE04 - Chunk # 1 de 5\n",
      "  - tempo de operação 15.2s\n",
      "3411 tokens usados para extrair 15 relações\n",
      "doc_id SAMUE04 - Chunk # 2 de 5\n",
      "  - tempo de operação 12.4s\n",
      "3188 tokens usados para extrair 12 relações\n",
      "doc_id SAMUE04 - Chunk # 3 de 5\n",
      "  - tempo de operação 16.1s\n",
      "3321 tokens usados para extrair 13 relações\n",
      "doc_id SAMUE04 - Chunk # 4 de 5\n",
      "  - tempo de operação 10.2s\n",
      "3223 tokens usados para extrair 12 relações\n",
      "doc_id SAMUE04 - Chunk # 5 de 5\n",
      "  - tempo de operação 3.3s\n",
      "2450 tokens usados para extrair 3 relações\n",
      "doc_id SAMUE05 - Chunk # 1 de 8\n",
      "  - tempo de operação 7.3s\n",
      "3155 tokens usados para extrair 8 relações\n",
      "doc_id SAMUE05 - Chunk # 2 de 8\n",
      "  - tempo de operação 8.1s\n",
      "2991 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE05 - Chunk # 3 de 8\n",
      "  - tempo de operação 15.5s\n",
      "3424 tokens usados para extrair 14 relações\n",
      "doc_id SAMUE05 - Chunk # 4 de 8\n",
      "  - tempo de operação 10.6s\n",
      "2924 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE05 - Chunk # 5 de 8\n",
      "  - tempo de operação 17.5s\n",
      "3497 tokens usados para extrair 14 relações\n",
      "doc_id SAMUE05 - Chunk # 6 de 8\n",
      "  - tempo de operação 8.7s\n",
      "3134 tokens usados para extrair 8 relações\n",
      "doc_id SAMUE05 - Chunk # 7 de 8\n",
      "  - tempo de operação 8.4s\n",
      "3029 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE05 - Chunk # 8 de 8\n",
      "  - tempo de operação 22.9s\n",
      "3954 tokens usados para extrair 23 relações\n",
      "doc_id SAMUE06 - Chunk # 1 de 2\n",
      "  - tempo de operação 8.4s\n",
      "3281 tokens usados para extrair 11 relações\n",
      "doc_id SAMUE06 - Chunk # 2 de 2\n",
      "  - tempo de operação 7.3s\n",
      "2706 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE07 - Chunk # 1 de 2\n",
      "  - tempo de operação 17.1s\n",
      "3404 tokens usados para extrair 14 relações\n",
      "doc_id SAMUE07 - Chunk # 2 de 2\n",
      "  - tempo de operação 9.1s\n",
      "2934 tokens usados para extrair 12 relações\n",
      "doc_id SAMUE08 - Chunk # 1 de 4\n",
      "  - tempo de operação 6.2s\n",
      "2810 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE08 - Chunk # 2 de 4\n",
      "  - tempo de operação 16.9s\n",
      "3310 tokens usados para extrair 10 relações\n",
      "doc_id SAMUE08 - Chunk # 3 de 4\n",
      "  - tempo de operação 10.1s\n",
      "3086 tokens usados para extrair 11 relações\n",
      "doc_id SAMUE08 - Chunk # 4 de 4\n",
      "  - tempo de operação 10.4s\n",
      "2871 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE09 - Chunk # 1 de 1\n",
      "  - tempo de operação 7.9s\n",
      "2931 tokens usados para extrair 11 relações\n",
      "doc_id SAMUE10 - Chunk # 1 de 1\n",
      "  - tempo de operação 10.1s\n",
      "2704 tokens usados para extrair 7 relações\n",
      "doc_id SAMUE11 - Chunk # 1 de 2\n",
      "  - tempo de operação 9.5s\n",
      "3144 tokens usados para extrair 9 relações\n",
      "doc_id SAMUE11 - Chunk # 2 de 2\n",
      "  - tempo de operação 9.1s\n",
      "2759 tokens usados para extrair 7 relações\n",
      "doc_id FELIP00 - Chunk # 1 de 3\n",
      "  - tempo de operação 11.2s\n",
      "3329 tokens usados para extrair 14 relações\n",
      "doc_id FELIP00 - Chunk # 2 de 3\n",
      "  - tempo de operação 6.6s\n",
      "2885 tokens usados para extrair 7 relações\n",
      "doc_id FELIP00 - Chunk # 3 de 3\n",
      "  - tempo de operação 5.5s\n",
      "2697 tokens usados para extrair 7 relações\n",
      "doc_id FELIP01 - Chunk # 1 de 1\n",
      "  - tempo de operação 8.3s\n",
      "2643 tokens usados para extrair 7 relações\n",
      "doc_id FELIP02 - Chunk # 1 de 1\n",
      "  - tempo de operação 7.3s\n",
      "2559 tokens usados para extrair 5 relações\n",
      "doc_id FELIP03 - Chunk # 1 de 1\n",
      "  - tempo de operação 5.8s\n",
      "2542 tokens usados para extrair 5 relações\n",
      "doc_id FELIP04 - Chunk # 1 de 1\n",
      "  - tempo de operação 6.7s\n",
      "2693 tokens usados para extrair 8 relações\n",
      "doc_id FELIP05 - Chunk # 1 de 1\n",
      "  - tempo de operação 8.6s\n",
      "2886 tokens usados para extrair 11 relações\n",
      "doc_id FELIP06 - Chunk # 1 de 1\n",
      "  - tempo de operação 4.7s\n",
      "2462 tokens usados para extrair 5 relações\n",
      "doc_id FELIP07 - Chunk # 1 de 1\n",
      "  - tempo de operação 6.8s\n",
      "2607 tokens usados para extrair 7 relações\n",
      "doc_id FELIP08 - Chunk # 1 de 1\n",
      "  - tempo de operação 4.9s\n",
      "2487 tokens usados para extrair 5 relações\n",
      "doc_id FELIP09 - Chunk # 1 de 1\n",
      "  - tempo de operação 5.1s\n",
      "2585 tokens usados para extrair 7 relações\n",
      "doc_id FELIP10 - Chunk # 1 de 1\n",
      "  - tempo de operação 6.1s\n",
      "2607 tokens usados para extrair 7 relações\n",
      "doc_id FELIP11 - Chunk # 1 de 1\n",
      "  - tempo de operação 4.5s\n",
      "2505 tokens usados para extrair 5 relações\n",
      "doc_id FELIP12 - Chunk # 1 de 1\n",
      "  - tempo de operação 8.6s\n",
      "2448 tokens usados para extrair 4 relações\n",
      "doc_id FELIP13 - Chunk # 1 de 1\n",
      "  - tempo de operação 3.8s\n",
      "2419 tokens usados para extrair 3 relações\n",
      "doc_id FELIP14 - Chunk # 1 de 1\n",
      "  - tempo de operação 4.7s\n",
      "2496 tokens usados para extrair 4 relações\n",
      "doc_id FELIP15 - Chunk # 1 de 1\n",
      "  - tempo de operação 9.2s\n",
      "2864 tokens usados para extrair 11 relações\n"
     ]
    }
   ],
   "source": [
    "# EXTRAIR\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\".\\n\"],chunk_size = 2000, chunk_overlap=0)\n",
    "\n",
    "final_json = []\n",
    "for doc in all_docs:\n",
    "    chunked_docs = text_splitter.split_documents([doc])\n",
    "    n=1\n",
    "    for chunked_doc in chunked_docs:\n",
    "        print(\"doc_id\", doc.id, \"- Chunk #\", n, \"de\", len(chunked_docs))\n",
    "        extracted_relations, tokens_used = extract_information(chunked_doc.page_content, doc_id)\n",
    "        extracted_relations = ajustar_output(extracted_relations)\n",
    "        print(tokens_used, \"tokens usados para extrair\", len(extracted_relations), \"relações\")\n",
    "        final_json.append({\"doc_id\": doc.id, \"elements\": extracted_relations})\n",
    "        n = n + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpar caracteres inválidos no final_json (aspas simples e duplas causam falhas no carregamento do grafo)\n",
    "for i in range(len(final_json)):\n",
    "    for j in range(len(final_json[i]['elements'])):\n",
    "        if final_json[i]['elements'][j]['item_type'] == 'node':\n",
    "            final_json[i]['elements'][j]['node_name'] = final_json[i]['elements'][j]['node_name'].replace('\"', '')\n",
    "            final_json[i]['elements'][j]['node_name'] = final_json[i]['elements'][j]['node_name'].replace(\"'\", \"\")\n",
    "            final_json[i]['elements'][j]['node_description'] = final_json[i]['elements'][j]['node_description'].replace('\"', '')\n",
    "            final_json[i]['elements'][j]['node_description'] = final_json[i]['elements'][j]['node_description'].replace(\"'\", \"\")\n",
    "        else:\n",
    "            final_json[i]['elements'][j]['head_node'] = final_json[i]['elements'][j]['head_node'].replace('\"', '')\n",
    "            final_json[i]['elements'][j]['head_node'] = final_json[i]['elements'][j]['head_node'].replace(\"'\", \"\")\n",
    "            final_json[i]['elements'][j]['tail_node'] = final_json[i]['elements'][j]['tail_node'].replace('\"', '')\n",
    "            final_json[i]['elements'][j]['tail_node'] = final_json[i]['elements'][j]['tail_node'].replace(\"'\", \"\")\n",
    "\n",
    "#limpar caracteres invalidos no all_docs\n",
    "\n",
    "for i in range(len(all_docs)):\n",
    "    all_docs[i].page_content = all_docs[i].page_content.replace('\"', '')\n",
    "    all_docs[i].page_content = all_docs[i].page_content.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar informação extraída\n",
    "\n",
    "with open('entidades_full.pkl', 'wb') as f:\n",
    "    pickle.dump(final_json, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRAGvEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
